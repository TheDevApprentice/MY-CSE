// app/controllers/events_controller.ts

import type { HttpContext } from '@adonisjs/core/http'
import Event from '#models/event'
import Subject from '#models/subject'
import Post from '#models/post'
import User from '#models/user'
import { DateTime } from 'luxon'
import redis from '@adonisjs/redis/services/main'

export default class EventsController {
  // Liste tous les √©v√©nements (avec cache Redis)
  async index({ request, response }: HttpContext) {
    try {
      // üõ°Ô∏è AJOUT : Rate limiting (100 requ√™tes par IP par heure)
      const clientIp = request.ip()
      const rateLimitKey = `rate_limit:events_list:${clientIp}`
      const requests = await redis.incr(rateLimitKey)
      
      if (requests === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (requests > 100) {
        return response.status(429).json({
          error: 'Trop de requ√™tes. Limite : 100 par heure.',
          retryAfter: 3600
        })
      }

      // ‚ö° AJOUT : Essaie de r√©cup√©rer depuis le cache Redis d'abord
      const cacheKey = 'events:all'
      const cachedEvents = await redis.get(cacheKey)
      
      if (cachedEvents) {
        const events = JSON.parse(cachedEvents)
        return response.ok({
          success: true,
          data: events,
          fromCache: true,
          cachedAt: new Date().toISOString()
        })
      }

      // üìö CONSERV√â : Requ√™te MySQL originale
      const events = await Event.all()
      const serializedEvents = events.map(event => event.serialize())

      // ‚ö° AJOUT : Met en cache pour 30 minutes (√©v√©nements changent mod√©r√©ment)
      await redis.setex(cacheKey, 1800, JSON.stringify(serializedEvents))

      return response.ok({
        success: true,
        data: serializedEvents,
        fromCache: false
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la r√©cup√©ration des √©v√©nements',
        message: error.message
      })
    }
  }

  // Affiche un √©v√©nement (avec cache Redis)
  async show({ params, request, response }: HttpContext) {
    try {
      // üõ°Ô∏è AJOUT : Rate limiting (200 requ√™tes par IP par heure)
      const clientIp = request.ip()
      const rateLimitKey = `rate_limit:event_show:${clientIp}`
      const requests = await redis.incr(rateLimitKey)
      
      if (requests === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (requests > 200) {
        return response.status(429).json({
          error: 'Trop de requ√™tes. Limite : 200 par heure.',
          retryAfter: 3600
        })
      }

      // ‚ö° AJOUT : Essaie de r√©cup√©rer depuis le cache Redis d'abord
      const cacheKey = `event:${params.id}`
      const cachedEvent = await redis.get(cacheKey)
      
      if (cachedEvent) {
        const event = JSON.parse(cachedEvent)
        return response.ok({
          success: true,
          data: event,
          fromCache: true,
          cachedAt: new Date().toISOString()
        })
      }

      // üìö CONSERV√â : Requ√™te MySQL originale
      const event = await Event.find(params.id)
      if (!event) {
        return response.notFound({ 
          success: false,
          message: 'Event not found' 
        })
      }

      const serializedEvent = event.serialize()

      // ‚ö° AJOUT : Met en cache pour 1 heure
      await redis.setex(cacheKey, 3600, JSON.stringify(serializedEvent))

      return response.ok({
        success: true,
        data: serializedEvent,
        fromCache: false
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la r√©cup√©ration de l\'√©v√©nement',
        message: error.message
      })
    }
  }

  // Cr√©e un √©v√©nement (avec invalidation cache Redis)
  async store({ request, response, auth }: HttpContext) {
    try {
      // üõ°Ô∏è AJOUT : Rate limiting cr√©ation √©v√©nements (5 cr√©ations par utilisateur par heure)
      const user = auth.user
      if (!user) {
        return response.status(401).json({ error: 'Utilisateur non authentifi√©' })
      }

      const rateLimitKey = `rate_limit:create_event:${user.id}`
      const events = await redis.incr(rateLimitKey)
      
      if (events === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (events > 5) {
        return response.status(429).json({
          error: 'Trop d\'√©v√©nements cr√©√©s. Limite : 5 par heure.',
          retryAfter: 3600
        })
      }

      // üìö CONSERV√â : Toute la logique de cr√©ation originale
      const data = request.only([
        'title', 'description', 'startDate', 'endDate', 'location', 
        'subjectId', 'postId', 'publishedAt', 'status'
      ])
      
      const event = await Event.create({
        ...data,
        createdBy: user.id,
      })

      // ‚ö° AJOUT : Invalide les caches d'√©v√©nements
      await redis.del('events:all') // Liste de tous les √©v√©nements
      await redis.del('events:published') // √âv√©nements publi√©s (si cache existe)
      await redis.del('events:upcoming') // √âv√©nements √† venir (si cache existe)

      return response.created({
        success: true,
        data: event.serialize(),
        cacheInvalidated: true
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la cr√©ation de l\'√©v√©nement',
        message: error.message
      })
    }
  }

  // Met √† jour un √©v√©nement (avec invalidation cache Redis)
  async update({ params, request, response, auth }: HttpContext) {
    try {
      // üõ°Ô∏è AJOUT : Rate limiting modification √©v√©nements (10 modifications par utilisateur par heure)
      const user = auth.user
      if (!user) {
        return response.status(401).json({ error: 'Utilisateur non authentifi√©' })
      }

      const rateLimitKey = `rate_limit:update_event:${user.id}`
      const updates = await redis.incr(rateLimitKey)
      
      if (updates === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (updates > 10) {
        return response.status(429).json({
          error: 'Trop de modifications d\'√©v√©nements. Limite : 10 par heure.',
          retryAfter: 3600
        })
      }

      // üìö CONSERV√â : Toute la logique de modification originale
      const event = await Event.find(params.id)
      if (!event) {
        return response.notFound({ 
          success: false,
          message: 'Event not found' 
        })
      }

      const data = request.only([
        'title', 'description', 'startDate', 'endDate', 'location', 
        'subjectId', 'postId', 'publishedAt', 'status'
      ])
      
      event.merge(data)
      await event.save()

      // ‚ö° AJOUT : Invalide les caches li√©s √† cet √©v√©nement
      await redis.del('events:all') // Liste de tous les √©v√©nements
      await redis.del(`event:${params.id}`) // Cache de cet √©v√©nement sp√©cifique
      await redis.del('events:published') // √âv√©nements publi√©s (si cache existe)
      await redis.del('events:upcoming') // √âv√©nements √† venir (si cache existe)

      return response.ok({
        success: true,
        data: event.serialize(),
        cacheInvalidated: true
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la modification de l\'√©v√©nement',
        message: error.message
      })
    }
  }

  // Supprime un √©v√©nement (avec invalidation cache Redis)
  async destroy({ params, response, auth }: HttpContext) {
    try {
      // üõ°Ô∏è AJOUT : Rate limiting suppression √©v√©nements (3 suppressions par utilisateur par heure)
      const user = auth.user
      if (!user) {
        return response.status(401).json({ error: 'Utilisateur non authentifi√©' })
      }

      const rateLimitKey = `rate_limit:delete_event:${user.id}`
      const deletions = await redis.incr(rateLimitKey)
      
      if (deletions === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (deletions > 3) {
        return response.status(429).json({
          error: 'Trop de suppressions d\'√©v√©nements. Limite : 3 par heure.',
          retryAfter: 3600
        })
      }

      // üìö CONSERV√â : Toute la logique de suppression originale
      const event = await Event.find(params.id)
      if (!event) {
        return response.notFound({ 
          success: false,
          message: 'Event not found' 
        })
      }

      await event.delete()

      // ‚ö° AJOUT : Invalide les caches li√©s √† cet √©v√©nement
      await redis.del('events:all') // Liste de tous les √©v√©nements
      await redis.del(`event:${params.id}`) // Cache de cet √©v√©nement sp√©cifique
      await redis.del('events:published') // √âv√©nements publi√©s (si cache existe)
      await redis.del('events:upcoming') // √âv√©nements √† venir (si cache existe)

      return response.noContent()
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la suppression de l\'√©v√©nement',
        message: error.message
      })
    }
  }

  // Publie un √©v√©nement imm√©diatement (avec invalidation cache Redis)
  async publish({ params, response, auth }: HttpContext) {
    try {
      // üõ°Ô∏è AJOUT : Rate limiting publication √©v√©nements (10 publications par utilisateur par heure)
      const user = auth.user
      if (!user) {
        return response.status(401).json({ error: 'Utilisateur non authentifi√©' })
      }

      const rateLimitKey = `rate_limit:publish_event:${user.id}`
      const publications = await redis.incr(rateLimitKey)
      
      if (publications === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (publications > 10) {
        return response.status(429).json({
          error: 'Trop de publications d\'√©v√©nements. Limite : 10 par heure.',
          retryAfter: 3600
        })
      }

      // üìö CONSERV√â : Toute la logique de publication originale
      const event = await Event.find(params.id)
      if (!event) {
        return response.notFound({ 
          success: false,
          message: 'Event not found' 
        })
      }

      event.status = 'published'
      event.publishedAt = DateTime.now()
      await event.save()

      // ‚ö° AJOUT : Invalide les caches li√©s aux √©v√©nements publi√©s
      await redis.del('events:all') // Liste de tous les √©v√©nements
      await redis.del(`event:${params.id}`) // Cache de cet √©v√©nement sp√©cifique
      await redis.del('events:published') // √âv√©nements publi√©s (si cache existe)
      await redis.del('events:upcoming') // √âv√©nements √† venir (si cache existe)

      return response.ok({
        success: true,
        data: event.serialize(),
        cacheInvalidated: true
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la publication de l\'√©v√©nement',
        message: error.message
      })
    }
  }

  // ‚ö° AJOUT : Nouvelles m√©thodes avec cache Redis pour am√©liorer l'API

  // GET /v1/events/published - √âv√©nements publi√©s avec cache
  async getPublishedEvents({ request, response }: HttpContext) {
    try {
      // üõ°Ô∏è Rate limiting
      const clientIp = request.ip()
      const rateLimitKey = `rate_limit:events_published:${clientIp}`
      const requests = await redis.incr(rateLimitKey)
      
      if (requests === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (requests > 150) {
        return response.status(429).json({
          error: 'Trop de requ√™tes. Limite : 150 par heure.',
          retryAfter: 3600
        })
      }

      // ‚ö° Cache des √©v√©nements publi√©s
      const cacheKey = 'events:published'
      const cachedEvents = await redis.get(cacheKey)
      
      if (cachedEvents) {
        const events = JSON.parse(cachedEvents)
        return response.ok({
          success: true,
          data: events,
          fromCache: true,
          cachedAt: new Date().toISOString()
        })
      }

      // Requ√™te MySQL pour √©v√©nements publi√©s
      const events = await Event.query().where('status', 'published').orderBy('publishedAt', 'desc')
      const serializedEvents = events.map(event => event.serialize())

      // Cache pour 20 minutes (√©v√©nements publi√©s changent moins souvent)
      await redis.setex(cacheKey, 1200, JSON.stringify(serializedEvents))

      return response.ok({
        success: true,
        data: serializedEvents,
        fromCache: false
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la r√©cup√©ration des √©v√©nements publi√©s',
        message: error.message
      })
    }
  }

  // GET /v1/events/upcoming - √âv√©nements √† venir avec cache
  async getUpcomingEvents({ request, response }: HttpContext) {
    try {
      // üõ°Ô∏è Rate limiting
      const clientIp = request.ip()
      const rateLimitKey = `rate_limit:events_upcoming:${clientIp}`
      const requests = await redis.incr(rateLimitKey)
      
      if (requests === 1) {
        await redis.expire(rateLimitKey, 3600) // 1 heure
      }
      
      if (requests > 150) {
        return response.status(429).json({
          error: 'Trop de requ√™tes. Limite : 150 par heure.',
          retryAfter: 3600
        })
      }

      // ‚ö° Cache des √©v√©nements √† venir
      const cacheKey = 'events:upcoming'
      const cachedEvents = await redis.get(cacheKey)
      
      if (cachedEvents) {
        const events = JSON.parse(cachedEvents)
        return response.ok({
          success: true,
          data: events,
          fromCache: true,
          cachedAt: new Date().toISOString()
        })
      }

      // Requ√™te MySQL pour √©v√©nements futurs
      const now = DateTime.now()
      const events = await Event.query()
        .where('startDate', '>', now.toSQL())
        .andWhere('status', 'published')
        .orderBy('startDate', 'asc')
        .limit(50) // Limite raisonnable

      const serializedEvents = events.map(event => event.serialize())

      // Cache pour 10 minutes (√©v√©nements √† venir peuvent changer souvent)
      await redis.setex(cacheKey, 600, JSON.stringify(serializedEvents))

      return response.ok({
        success: true,
        data: serializedEvents,
        fromCache: false
      })
    } catch (error) {
      return response.status(500).json({
        error: 'Erreur lors de la r√©cup√©ration des √©v√©nements √† venir',
        message: error.message
      })
    }
  }
}